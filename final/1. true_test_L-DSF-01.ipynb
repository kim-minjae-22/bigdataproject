{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 모델 로드\n",
    "xgb_model = joblib.load(r\"C:\\Users\\KIM\\Desktop\\bigdataproject\\bigdataproject\\final\\FinalTrainedModels\\xgboost_model_with_pca.joblib\")\n",
    "rf_model = joblib.load(r\"C:\\Users\\KIM\\Desktop\\bigdataproject\\bigdataproject\\final\\FinalTrainedModels\\randomforest_model_with_pca.joblib\")\n",
    "\n",
    "# 기존 학습에서 사용했던 scaler와 PCA 로드\n",
    "scaler = joblib.load(r\"C:\\Users\\KIM\\Desktop\\bigdataproject\\bigdataproject\\final\\FinalTrainedModels\\scaler_model.joblib\")  # 학습 시 저장된 scaler 파일\n",
    "pca = joblib.load(r\"C:\\Users\\KIM\\Desktop\\bigdataproject\\bigdataproject\\final\\FinalTrainedModels\\pca_model.joblib\")  # 학습 시 저장된 PCA 파일\n",
    "\n",
    "# 메타데이터 추출 함수\n",
    "def extract_metadata(file_path):\n",
    "    metadata = {}\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "        \n",
    "        # 파일에서 메타데이터 추출\n",
    "        for line in lines:\n",
    "            if line.startswith('Date'):\n",
    "                metadata['Date'] = line.strip().split(',')[1]\n",
    "            elif line.startswith('Filename'):\n",
    "                metadata['Filename'] = line.strip().split(',')[1]\n",
    "            elif line.startswith('Data Label'):\n",
    "                metadata['Data Label'] = line.strip().split(',')[1]\n",
    "            elif line.startswith('Label No'):\n",
    "                metadata['Label No'] = line.strip().split(',')[1]\n",
    "            elif line.startswith('Motor Spec'):\n",
    "                motor_spec = line.strip().split(',')[1:]\n",
    "                metadata['Motor Spec'] = motor_spec\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "# 센서 데이터 추출 함수\n",
    "def extract_sensor_data(file_path):\n",
    "    # 파일에서 센서 데이터를 읽기\n",
    "    data = pd.read_csv(file_path, skiprows=10, header=None)\n",
    "    data.columns = ['time','Sensor1', 'Sensor2', 'Sensor3','']\n",
    "    return data\n",
    "\n",
    "# 피처 계산 함수\n",
    "def calculate_features(data):\n",
    "    features = {}\n",
    "\n",
    "    # 절댓값 평균\n",
    "    features['Mean'] = np.mean(np.abs(data))\n",
    "\n",
    "    # 절댓값 최대값\n",
    "    features['Max'] = np.max(np.abs(data))\n",
    "\n",
    "    # RMS (Root Mean Square)\n",
    "    features['RMS'] = np.sqrt(np.mean(data ** 2))\n",
    "\n",
    "    # Skewness\n",
    "    features['Skewness'] = pd.Series(data).skew()\n",
    "\n",
    "    # Kurtosis\n",
    "    features['Kurtosis'] = pd.Series(data).kurt()\n",
    "\n",
    "    # Crest Factor\n",
    "    rms = features['RMS']\n",
    "    features['Crest Factor'] = features['Max'] / rms if rms != 0 else 0\n",
    "\n",
    "    # Impulse Factor\n",
    "    mean = features['Mean']\n",
    "    features['Impulse Factor'] = features['Max'] / mean if mean != 0 else 0\n",
    "\n",
    "    # Shape Factor\n",
    "    features['Shape Factor'] = rms / mean if mean != 0 else 0\n",
    "\n",
    "    return features\n",
    "\n",
    "# 데이터 처리 함수\n",
    "def load_and_process_new_data(file_path, scaler, pca, feature_names=None):\n",
    "    # 메타데이터 추출\n",
    "    metadata = extract_metadata(file_path)\n",
    "    \n",
    "    # 센서 데이터 추출\n",
    "    sensor_data = extract_sensor_data(file_path)\n",
    "\n",
    "    # 각 센서별 피처 계산\n",
    "    overall_features = {'Label': metadata['Label No']}\n",
    "    for sensor in ['Sensor1', 'Sensor2', 'Sensor3']:\n",
    "        features = calculate_features(sensor_data[sensor].values)\n",
    "        for feature_name, value in features.items():\n",
    "            overall_features[f'{sensor}_{feature_name}'] = value\n",
    "\n",
    "    # Motor Spec_Period 추가 (예시: motor spec에서 주기를 계산하여 추가)\n",
    "    motor_spec_period = 1  # 예시로 1로 설정, 실제 계산 필요\n",
    "    overall_features['Motor Spec_Period'] = motor_spec_period\n",
    "\n",
    "    # 피처와 레이블을 데이터프레임으로 변환\n",
    "    combined_df = pd.DataFrame([overall_features])\n",
    "\n",
    "    # 피처 (X)와 레이블 (y) 분리\n",
    "    X = combined_df.drop(columns=['Label'])\n",
    "    y = combined_df['Label']\n",
    "\n",
    "    # feature_names에 맞춰서 새 데이터의 순서를 정렬\n",
    "    if feature_names:\n",
    "        X = X[feature_names]  # 학습 시 사용한 특성 순서로 정렬\n",
    "\n",
    "    # 데이터 스케일링\n",
    "    X_scaled = scaler.transform(X)\n",
    "\n",
    "    # PCA 적용\n",
    "    X_pca = pca.transform(X_scaled)\n",
    "\n",
    "    return X_pca, y\n",
    "\n",
    "# 디렉토리 내 모든 파일 처리\n",
    "def process_all_files_in_directory(directory_path, scaler, pca, xgb_model, rf_model, feature_names=None):\n",
    "    result = []  # 결과를 저장할 리스트\n",
    "\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".csv\"):  # .csv 파일을 처리\n",
    "                file_path = os.path.join(root, file)\n",
    "                print(f\"Processing file: {file_path}\")\n",
    "\n",
    "                # 새로운 데이터에 대해 처리 및 예측 수행\n",
    "                X_new_pca, y_new = load_and_process_new_data(file_path, scaler, pca, feature_names)\n",
    "\n",
    "                # 예측 수행 (XGBoost 모델)\n",
    "                xgb_pred = xgb_model.predict(X_new_pca)\n",
    "                print(f\"XGBoost Prediction for {file}: {xgb_pred}\")\n",
    "\n",
    "                # 예측 수행 (RandomForest 모델)\n",
    "                rf_pred = rf_model.predict(X_new_pca)\n",
    "                print(f\"RandomForest Prediction for {file}: {rf_pred}\")\n",
    "\n",
    "                # 결과를 리스트에 저장\n",
    "                result.append({\n",
    "                    'Filename': file,\n",
    "                    'XGBoost Prediction': xgb_pred[0],\n",
    "                    'RandomForest Prediction': rf_pred[0],\n",
    "                    'True Label': y_new.values[0]\n",
    "                })\n",
    "    \n",
    "    # 결과를 데이터프레임으로 변환\n",
    "    result_df = pd.DataFrame(result)\n",
    "\n",
    "    # 예측값 매핑: 0 → 'N', 1 → 'E1', 2 → 'E2', 3 → 'E3', 4 → 'E4'\n",
    "    label_mapping = {0: 'N', 1: 'E1', 2: 'E2', 3: 'E3', 4: 'E4'}\n",
    "    result_df['XGBoost Prediction Label'] = result_df['XGBoost Prediction'].map(label_mapping)\n",
    "    result_df['RandomForest Prediction Label'] = result_df['RandomForest Prediction'].map(label_mapping)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "# 불량 유형 비율 계산 함수\n",
    "def calculate_defect_ratios(result_df):\n",
    "    for model in ['XGBoost', 'RandomForest']:\n",
    "        print(f\"\\n{model} Model 비율 계산:\")\n",
    "\n",
    "        total_count = result_df.shape[0]\n",
    "        \n",
    "        # 정상(N) 비율 계산\n",
    "        normal_count = result_df[result_df[f'{model} Prediction Label'] == 'N'].shape[0]\n",
    "        normal_ratio = normal_count / total_count if total_count > 0 else 0\n",
    "        print(f\"  정상 (N) 비율: {normal_ratio * 100:.2f}%\")\n",
    "        \n",
    "        # 불량 유형별 비율 계산\n",
    "        for defect_type in ['E1', 'E2', 'E3', 'E4']:\n",
    "            defect_count = result_df[result_df[f'{model} Prediction Label'] == defect_type].shape[0]\n",
    "            defect_ratio = defect_count / total_count if total_count > 0 else 0\n",
    "            print(f\"  {defect_type} 비율: {defect_ratio * 100:.2f}%\")\n",
    "\n",
    "# 학습 데이터에서 특성 이름 추출\n",
    "feature_names = [\n",
    "    'Sensor1_Mean', 'Sensor1_Max', 'Sensor1_RMS', 'Sensor1_Skewness', 'Sensor1_Kurtosis', \n",
    "    'Sensor1_Crest Factor', 'Sensor1_Impulse Factor', 'Sensor1_Shape Factor', \n",
    "    'Sensor2_Mean', 'Sensor2_Max', 'Sensor2_RMS', 'Sensor2_Skewness', 'Sensor2_Kurtosis', \n",
    "    'Sensor2_Crest Factor', 'Sensor2_Impulse Factor', 'Sensor2_Shape Factor', \n",
    "    'Sensor3_Mean', 'Sensor3_Max', 'Sensor3_RMS', 'Sensor3_Skewness', 'Sensor3_Kurtosis', \n",
    "    'Sensor3_Crest Factor', 'Sensor3_Impulse Factor', 'Sensor3_Shape Factor',\n",
    "    'Motor Spec_Period'  # Motor Spec_Period 추가\n",
    "]\n",
    "\n",
    "# 디렉토리 경로\n",
    "directory_path = r\"D://기계시설물 고장 예지 센서//Validation//current//2.2kW//L-SF-04//정상\"  # 여기에 새로운 데이터 파일이 들어있는 디렉토리 경로를 입력\n",
    "\n",
    "# 디렉토리 내 모든 파일 처리 및 결과 출력\n",
    "result_df = process_all_files_in_directory(directory_path, scaler, pca, xgb_model, rf_model, feature_names=feature_names)\n",
    "print(\"\\nPrediction Results:\")\n",
    "print(result_df)\n",
    "\n",
    "# 불량 유형 비율 계산\n",
    "calculate_defect_ratios(result_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
