{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb2ec680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\kim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.1.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\kim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from xgboost) (2.2.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\kim\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from xgboost) (1.14.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\KIM\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60683672-03f4-4b28-8235-c3e95b917860",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'XGBOOST Prediction'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 189\u001b[0m\n\u001b[0;32m    186\u001b[0m directory_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m기계시설물 고장 예지 센서\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcurrent\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m남은파일\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mL-SF-04\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m베어링불량\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# 여기에 새로운 데이터 파일이 들어있는 디렉토리 경로를 입력\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;66;03m# 디렉토리 내 모든 파일 처리 및 결과 출력\u001b[39;00m\n\u001b[1;32m--> 189\u001b[0m result_df \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_all_files_in_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpca\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXGB_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRDF_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPrediction Results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28mprint\u001b[39m(result_df)\n",
      "Cell \u001b[1;32mIn[9], line 151\u001b[0m, in \u001b[0;36mprocess_all_files_in_directory\u001b[1;34m(directory_path, scaler, pca, XGB_model, RDF_model, feature_names)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# 예측값 매핑: 0 → 'N', 1 → 'E1', 2 → 'E2', 3 → 'E3', 4 → 'E4'\u001b[39;00m\n\u001b[0;32m    150\u001b[0m label_mapping \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m0\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m2\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m3\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE3\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m4\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE4\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[1;32m--> 151\u001b[0m result_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXGB Prediction Label\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mresult_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mXGBOOST Prediction\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmap(label_mapping)\n\u001b[0;32m    152\u001b[0m result_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRDF Prediction Label\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m result_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRandomForest Prediction\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(label_mapping)\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result_df\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'XGBOOST Prediction'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 모델 로드\n",
    "XGB_model = joblib.load(r\"C:\\Users\\KIM\\Desktop\\bigdataproject\\bigdataproject\\final\\final_final\\models-20250120T033752Z-001\\models\\xgboost_model_with_pca3rd.joblib\")\n",
    "RDF_model = joblib.load(r\"C:\\Users\\KIM\\Desktop\\bigdataproject\\bigdataproject\\final\\final_final\\models-20250120T033752Z-001\\models\\randomforest_model_with_pca3rd.joblib\")\n",
    "\n",
    "# 기존 학습에서 사용했던 scaler와 PCA 로드\n",
    "scaler = joblib.load(r\"C:\\Users\\KIM\\Desktop\\bigdataproject\\bigdataproject\\final\\final_final\\models-20250120T033752Z-001\\models\\scaler_model3rd.joblib\")  # 학습 시 저장된 scaler 파일\n",
    "pca = joblib.load(r\"C:\\Users\\KIM\\Desktop\\bigdataproject\\bigdataproject\\final\\final_final\\models-20250120T033752Z-001\\models\\pca_model3rd.joblib\")  # 학습 시 저장된 PCA 파일\n",
    "\n",
    "# 메타데이터 추출 함수\n",
    "def extract_metadata(file_path):\n",
    "    metadata = {}\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "        \n",
    "        # 파일에서 메타데이터 추출\n",
    "        for line in lines:\n",
    "            if line.startswith('Date'):\n",
    "                metadata['Date'] = line.strip().split(',')[1]\n",
    "            elif line.startswith('Filename'):\n",
    "                metadata['Filename'] = line.strip().split(',')[1]\n",
    "            elif line.startswith('Data Label'):\n",
    "                metadata['Data Label'] = line.strip().split(',')[1]\n",
    "            elif line.startswith('Label No'):\n",
    "                metadata['Label No'] = line.strip().split(',')[1]\n",
    "            elif line.startswith('Motor Spec'):\n",
    "                motor_spec = line.strip().split(',')[1:]\n",
    "                metadata['Motor Spec'] = motor_spec\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "# 센서 데이터 추출 함수\n",
    "def extract_sensor_data(file_path):\n",
    "    # 파일에서 센서 데이터를 읽기\n",
    "    data = pd.read_csv(file_path, skiprows=10, header=None)\n",
    "    data.columns = ['time','Sensor1', 'Sensor2', 'Sensor3','']\n",
    "    return data\n",
    "\n",
    "# 피처 계산 함수\n",
    "def calculate_features(data):\n",
    "    features = {}\n",
    "\n",
    "    # 절댓값 평균\n",
    "    features['Mean'] = np.mean(np.abs(data))\n",
    "\n",
    "    # 절댓값 최대값\n",
    "    features['Max'] = np.max(np.abs(data))\n",
    "\n",
    "    # RMS (Root Mean Square)\n",
    "    features['RMS'] = np.sqrt(np.mean(data ** 2))\n",
    "\n",
    "    # Skewness\n",
    "    features['Skewness'] = pd.Series(data).skew()\n",
    "\n",
    "    # Kurtosis\n",
    "    features['Kurtosis'] = pd.Series(data).kurt()\n",
    "\n",
    "    # Crest Factor\n",
    "    rms = features['RMS']\n",
    "    features['Crest Factor'] = features['Max'] / rms if rms != 0 else 0\n",
    "\n",
    "    # Impulse Factor\n",
    "    mean = features['Mean']\n",
    "    features['Impulse Factor'] = features['Max'] / mean if mean != 0 else 0\n",
    "\n",
    "    # Shape Factor\n",
    "    features['Shape Factor'] = rms / mean if mean != 0 else 0\n",
    "\n",
    "    return features\n",
    "\n",
    "# 데이터 처리 함수\n",
    "def load_and_process_new_data(file_path, scaler, pca, feature_names=None):\n",
    "    # 메타데이터 추출\n",
    "    metadata = extract_metadata(file_path)\n",
    "    \n",
    "    # 센서 데이터 추출\n",
    "    sensor_data = extract_sensor_data(file_path)\n",
    "\n",
    "    # 각 센서별 피처 계산\n",
    "    overall_features = {'Label': metadata['Label No']}\n",
    "    for sensor in ['Sensor1', 'Sensor2', 'Sensor3']:\n",
    "        features = calculate_features(sensor_data[sensor].values)\n",
    "        for feature_name, value in features.items():\n",
    "            overall_features[f'{sensor}_{feature_name}'] = value\n",
    "\n",
    "    # Motor Spec_Period 추가 (예시: motor spec에서 주기를 계산하여 추가)\n",
    "    motor_spec_period = 1  # 예시로 1로 설정, 실제 계산 필요\n",
    "    overall_features['Motor Spec_Period'] = motor_spec_period\n",
    "\n",
    "    # 피처와 레이블을 데이터프레임으로 변환\n",
    "    combined_df = pd.DataFrame([overall_features])\n",
    "\n",
    "    # 피처 (X)와 레이블 (y) 분리\n",
    "    X = combined_df.drop(columns=['Label'])\n",
    "    y = combined_df['Label']\n",
    "\n",
    "    # feature_names에 맞춰서 새 데이터의 순서를 정렬\n",
    "    if feature_names:\n",
    "        X = X[feature_names]  # 학습 시 사용한 특성 순서로 정렬\n",
    "\n",
    "    # 데이터 스케일링\n",
    "    X_scaled = scaler.transform(X)\n",
    "\n",
    "    # PCA 적용\n",
    "    X_pca = pca.transform(X_scaled)\n",
    "\n",
    "    return X_pca, y\n",
    "\n",
    "# 디렉토리 내 모든 파일 처리\n",
    "def process_all_files_in_directory(directory_path, scaler, pca, XGB_model, RDF_model, feature_names=None):\n",
    "    result = []  # 결과를 저장할 리스트\n",
    "\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".csv\"):  # .csv 파일을 처리\n",
    "                file_path = os.path.join(root, file)\n",
    "                print(f\"Processing file: {file_path}\")\n",
    "\n",
    "                # 새로운 데이터에 대해 처리 및 예측 수행\n",
    "                X_new_pca, y_new = load_and_process_new_data(file_path, scaler, pca, feature_names)\n",
    "\n",
    "                # 예측 수행 (XGBOOST 모델)\n",
    "                XGB_pred = XGB_model.predict(X_new_pca)\n",
    "                #print(f\"XGBOOST Prediction for {file}: {XGB_pred}\")\n",
    "\n",
    "                # 예측 수행 (RANDOMFOREST 모델)\n",
    "                RDF_pred = RDF_model.predict(X_new_pca)\n",
    "                #print(f\"RandomForest Prediction for {file}: {RDF_pred}\")\n",
    "\n",
    "                # 결과를 리스트에 저장\n",
    "                result.append({\n",
    "                    'Filename': file,\n",
    "                    'XGBOOST Prediction' : XGB_pred[0],\n",
    "                    'RandomForest Prediction': RDF_pred[0],\n",
    "                    'True Label': y_new.values[0]\n",
    "                })\n",
    "    \n",
    "    # 결과를 데이터프레임으로 변환\n",
    "    result_df = pd.DataFrame(result)\n",
    "\n",
    "    # 예측값 매핑: 0 → 'N', 1 → 'E1', 2 → 'E2', 3 → 'E3', 4 → 'E4'\n",
    "    label_mapping = {0: 'N', 1: 'E1', 2: 'E2', 3: 'E3', 4: 'E4'}\n",
    "    result_df['XGB Prediction Label'] = result_df['XGBOOST Prediction'].map(label_mapping)\n",
    "    result_df['RDF Prediction Label'] = result_df['RandomForest Prediction'].map(label_mapping)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "# 불량 유형 비율 계산 함수\n",
    "def calculate_defect_ratios(result_df):\n",
    "    for model in ['XGB', 'RDF']:\n",
    "        print(f\"\\n{model} Model 비율 계산:\")\n",
    "\n",
    "        total_count = result_df.shape[0]\n",
    "        \n",
    "        # 정상(N) 비율 계산\n",
    "        normal_count = result_df[result_df[f'{model} Prediction Label'] == 'N'].shape[0]\n",
    "        normal_ratio = normal_count / total_count if total_count > 0 else 0\n",
    "        print(f\"  정상 (N) 비율: {normal_ratio * 100:.2f}%\")\n",
    "        \n",
    "        # 불량 유형별 비율 계산\n",
    "        for defect_type in ['E1', 'E2', 'E3', 'E4']:\n",
    "            defect_count = result_df[result_df[f'{model} Prediction Label'] == defect_type].shape[0]\n",
    "            defect_ratio = defect_count / total_count if total_count > 0 else 0\n",
    "            print(f\"  {defect_type} 비율: {defect_ratio * 100:.2f}%\")\n",
    "\n",
    "# 학습 데이터에서 특성 이름 추출\n",
    "feature_names = [\n",
    "    'Sensor1_Mean', 'Sensor1_Max', 'Sensor1_RMS', 'Sensor1_Skewness', 'Sensor1_Kurtosis', \n",
    "    'Sensor1_Crest Factor', 'Sensor1_Impulse Factor', 'Sensor1_Shape Factor', \n",
    "    'Sensor2_Mean', 'Sensor2_Max', 'Sensor2_RMS', 'Sensor2_Skewness', 'Sensor2_Kurtosis', \n",
    "    'Sensor2_Crest Factor', 'Sensor2_Impulse Factor', 'Sensor2_Shape Factor', \n",
    "    'Sensor3_Mean', 'Sensor3_Max', 'Sensor3_RMS', 'Sensor3_Skewness', 'Sensor3_Kurtosis', \n",
    "    'Sensor3_Crest Factor', 'Sensor3_Impulse Factor', 'Sensor3_Shape Factor',\n",
    "    'Motor Spec_Period'  # Motor Spec_Period 추가\n",
    "]\n",
    "\n",
    "# 디렉토리 경로\n",
    "directory_path = r\"D:\\기계시설물 고장 예지 센서\\Training\\current\\남은파일\\L-SF-04\\베어링불량\"  # 여기에 새로운 데이터 파일이 들어있는 디렉토리 경로를 입력\n",
    "\n",
    "# 디렉토리 내 모든 파일 처리 및 결과 출력\n",
    "result_df = process_all_files_in_directory(directory_path, scaler, pca, XGB_model, RDF_model, feature_names=feature_names)\n",
    "print(\"\\nPrediction Results:\")\n",
    "print(result_df)\n",
    "\n",
    "# 불량 유형 비율 계산\n",
    "calculate_defect_ratios(result_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60db648-1de1-4c5d-b520-0eb2fd4ec9cd",
   "metadata": {},
   "source": [
    "# 시각화 자료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "839c8462-fbf0-4f43-89f7-23b3b2ca2d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\human\\AppData\\Local\\Temp\\ipykernel_6524\\1611297124.py:23: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=defect_labels, y=defect_values, palette=\"viridis\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved bar chart: C:\\Users\\human\\Desktop\\프로젝트 관련\\이미지들\\XGB_Prediction_Bar.jpg\n",
      "Saved pie chart: C:\\Users\\human\\Desktop\\프로젝트 관련\\이미지들\\XGB_Prediction_Pie.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\human\\AppData\\Local\\Temp\\ipykernel_6524\\1611297124.py:23: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=defect_labels, y=defect_values, palette=\"viridis\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved bar chart: C:\\Users\\human\\Desktop\\프로젝트 관련\\이미지들\\RDF_Prediction_Bar.jpg\n",
      "Saved pie chart: C:\\Users\\human\\Desktop\\프로젝트 관련\\이미지들\\RDF_Prediction_Pie.jpg\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "DataFrame.pivot() takes 1 positional argument but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 70\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# 함수 실행\u001b[39;00m\n\u001b[0;32m     69\u001b[0m visualize_defect_ratios(result_df, output_dir)  \u001b[38;5;66;03m# 불량 유형 비율 시각화 및 저장\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m visualize_model_comparison(result_df, output_dir)\n",
      "Cell \u001b[1;32mIn[6], line 54\u001b[0m, in \u001b[0;36mvisualize_model_comparison\u001b[1;34m(result_df, output_dir)\u001b[0m\n\u001b[0;32m     51\u001b[0m comparison\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXGB Prediction Label\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRDF Prediction Label\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     53\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m---> 54\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(comparison\u001b[38;5;241m.\u001b[39mpivot(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXGB Prediction Label\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRDF Prediction Label\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     55\u001b[0m             annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBlues\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     56\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXGBoost와 RandomForest 모델의 예측 결과 비교\u001b[39m\u001b[38;5;124m\"\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n\u001b[0;32m     57\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandomForest Prediction\u001b[39m\u001b[38;5;124m\"\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m14\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: DataFrame.pivot() takes 1 positional argument but 4 were given"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# 한글 폰트 설정 (필요한 경우)\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'  # 윈도우\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 마이너스 기호 깨짐 방지\n",
    "\n",
    "# 저장 경로 설정\n",
    "output_dir = r\"C:\\Users\\KIM\\Desktop\\bigdataproject\\bigdataproject\\final\\final_final\"  # 저장할 디렉토리 경로\n",
    "os.makedirs(output_dir, exist_ok=True)  # 디렉토리가 없으면 생성\n",
    "\n",
    "# 불량 유형 비율 시각화\n",
    "def visualize_defect_ratios(result_df, output_dir):\n",
    "    for model in ['XGB', 'RDF']:\n",
    "        # 불량 유형 비율 계산\n",
    "        defect_counts = result_df[f'{model} Prediction Label'].value_counts()\n",
    "        defect_labels = defect_counts.index\n",
    "        defect_values = defect_counts.values\n",
    "\n",
    "        # 막대그래프\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.barplot(x=defect_labels, y=defect_values, palette=\"viridis\")\n",
    "        plt.title(f\"{model} Model - 예측 결과 분포\", fontsize=16)\n",
    "        plt.xlabel(\"예측 라벨\", fontsize=14)\n",
    "        plt.ylabel(\"파일 개수\", fontsize=14)\n",
    "        plt.xticks(fontsize=12)\n",
    "        plt.yticks(fontsize=12)\n",
    "\n",
    "        # 저장\n",
    "        bar_output_path = os.path.join(output_dir, f\"{model}_Prediction_Bar.jpg\")\n",
    "        plt.savefig(bar_output_path, format=\"jpg\", dpi=300)\n",
    "        print(f\"Saved bar chart: {bar_output_path}\")\n",
    "        plt.close()\n",
    "\n",
    "        # 파이차트\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.pie(defect_values, labels=defect_labels, autopct='%1.1f%%', startangle=140, colors=sns.color_palette(\"viridis\", len(defect_labels)))\n",
    "        plt.title(f\"{model} Model - 예측 결과 비율\", fontsize=16)\n",
    "\n",
    "        # 저장\n",
    "        pie_output_path = os.path.join(output_dir, f\"{model}_Prediction_Pie.jpg\")\n",
    "        plt.savefig(pie_output_path, format=\"jpg\", dpi=300)\n",
    "        print(f\"Saved pie chart: {pie_output_path}\")\n",
    "        plt.close()\n",
    "\n",
    "# 모델 간 결과 비교 시각화\n",
    "def visualize_model_comparison(result_df, output_dir):\n",
    "    # XGBoost vs RandomForest의 예측 결과 비교\n",
    "    comparison = result_df[['XGB Prediction Label', 'RDF Prediction Label']].value_counts().reset_index()\n",
    "    comparison.columns = ['XGB Prediction Label', 'RDF Prediction Label', 'Count']\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(comparison.pivot(\"XGB Prediction Label\", \"RDF Prediction Label\", \"Count\"),\n",
    "                annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(\"XGBoost와 RandomForest 모델의 예측 결과 비교\", fontsize=16)\n",
    "    plt.xlabel(\"RandomForest Prediction\", fontsize=14)\n",
    "    plt.ylabel(\"XGBoost Prediction\", fontsize=14)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "\n",
    "    # 저장\n",
    "    heatmap_output_path = os.path.join(output_dir, \"Model_Comparison_Heatmap.jpg\")\n",
    "    plt.savefig(heatmap_output_path, format=\"jpg\", dpi=300)\n",
    "    print(f\"Saved heatmap: {heatmap_output_path}\")\n",
    "    plt.close()\n",
    "\n",
    "# 함수 실행\n",
    "visualize_defect_ratios(result_df, output_dir)  # 불량 유형 비율 시각화 및 저장\n",
    "visualize_model_comparison(result_df, output_dir)  # 모델 간 예측 비교 시각화 및 저장\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1e45db-71a5-455e-8da5-a1bd3fac1308",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
